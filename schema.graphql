"""Exposes a URL that specifies the behaviour of this scalar."""
directive @specifiedBy(
  """The URL that specifies the behaviour of this scalar."""
  url: String!
) on SCALAR

type AggregateInversionSolution implements Node & FileInterface & PredecessorsInterface & InversionSolutionInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]

  """When the solution was created"""
  created: DateTime

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  tables: [LabelledTableRelation]

  """deprecated"""
  hazard_table: Table

  """deprecated"""
  mfd_table: Table
  produced_by: AutomationTaskUnion
  common_rupture_set: File

  """The solutions used to build the aggregate"""
  source_solutions: [SourceSolutionUnion]

  """aggregation function on rupture rates."""
  aggregation_fn: AggregationFn
}

enum AggregationFn {
  MEAN
}

input AppendInversionSolutionTablesInput {
  id: ID
  tables: [LabelledTableRelationInput]!
  clientMutationId: String
}

"""Append LabelledTableRelationTable to an existing Inversion Solution"""
type AppendInversionSolutionTablesPayload {
  inversion_solution: InversionSolution
  ok: Boolean
  clientMutationId: String
}

type AutomationTask implements Node & Thing & AutomationTaskInterface {
  id: ID!

  """The time the event was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """parent task(s) of this task"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection
  result: EventResult
  state: EventState

  """the final duration of the event in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePair]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePair]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]
  model_type: ModelType
  task_type: TaskSubType

  """the primary result of this task (only for task_type == INVERSION."""
  inversion_solution: InversionSolution
}

input AutomationTaskInput {
  result: EventResult!
  state: EventState!

  """The time the task was created"""
  created: DateTime!

  """The final duraton of the task in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePairInput]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePairInput]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
}

"""An AutomationTask in the NSHM process"""
interface AutomationTaskInterface {
  result: EventResult
  state: EventState

  """The time the event was created"""
  created: DateTime

  """the final duration of the event in seconds"""
  duration: Float

  """parent task(s) of this task"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePair]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePair]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]
}

union AutomationTaskUnion = RuptureGenerationTask | AutomationTask

input AutomationTaskUpdateInput {
  task_id: ID!
  result: EventResult
  state: EventState

  """The final duraton of the task in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePairInput]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePairInput]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
}

"""
BigInt is an extension of the regular Int field
    that supports Integers bigger than a signed
    32-bit integer.
"""
scalar BigInt

type BranchAttributeValue {
  name: String
  long_name: String
  json_value: JSONString
}

type BranchAttributeValueSpec {
  name: String
  long_name: String
  value_options: JSONString
}

union ChildTaskUnion = GeneralTask | RuptureGenerationTask | AutomationTask | OpenquakeHazardTask

type ColorScale {
  name: String
  min_value: Float
  max_value: Float
  normalisation: ColourScaleNormaliseEnum
  color_map: HexRgbValueMapping
}

"""Arguments passed as ColorScaleArgsInput"""
input ColorScaleArgsInput {
  name: String = "inferno"
  min_value: Float
  max_value: Float
  normalisation: ColourScaleNormaliseEnum
}

enum ColourScaleNormalise {
  LOG
  LIN
}

enum ColourScaleNormaliseEnum {
  LOG
  LIN
}

type CompositeRuptureDetail implements Node {
  id: ID!
  model_id: String

  """Unique ID of the fault system e.g. `PUY`"""
  fault_system: String
  rupture_index: Int
  magnitude: Float

  """Rupture length in kilometres^2"""
  area: Float

  """Rupture length in kilometres)"""
  length: Float

  """average rake angle (degrees) of the entire rupture"""
  rake_mean: Float

  """mean of `rate` * `branch weight` of the contributing solutions"""
  rate_weighted_mean: Float

  """maximum rate from contributing solutions"""
  rate_max: Float

  """minimum rate from contributing solutions"""
  rate_min: Float

  """count of model solutions that include this rupture"""
  rate_count: Int
  fault_traces: JSONString
  fault_surfaces(
    """feature style for rupture trace geojson."""
    style: GeojsonAreaStyleArgumentsInput = {stroke_color: "black", stroke_width: 1, stroke_opacity: 1, fill_color: "green", fill_opacity: 1}
  ): JSONString
}

input CompositeRuptureDetailArgs {
  model_id: String

  """Unique ID of the fault system e.g. `PUY`"""
  fault_system: String
  rupture_index: Int
}

"""
A collection of ruptures and their fault sections that have a geojson represention.  They also
have a set of attributes derived from the composite solution e.g. rate_weighted_mean etc

Key attributes:
 - filter_arguments contains the filter criteria used to find the ruptures.
 - fault_surfaces is a geojson feature file based on the geometry from the undelying rutpure set.
   It may by styled by some attribute of the faults section.
 - mfd_histogram is the MFD table summarise the set of ruptures.
"""
type CompositeRuptureSections {
  model_id: String
  rupture_count: Int
  section_count: Int
  filter_arguments: FilterRupturesArgs

  """maximum rupture magnitude from the contributing solutions."""
  max_magnitude: Float

  """minimum rupture magnitude from the contributing solutions."""
  min_magnitude: Float

  """
  maximum section participation rate (sum of rate_weighted_mean.sum) over the contributing solutions.
  """
  max_participation_rate: Float

  """
  minimum section participation rate (sum of rate_weighted_mean.sum) over the contributing solutions.
  """
  min_participation_rate: Float
  fault_surfaces(color_scale: ColorScaleArgsInput, style: GeojsonAreaStyleArgumentsInput): JSONString
  fault_traces(color_scale: ColorScaleArgsInput, style: GeojsonLineStyleArgumentsInput): JSONString

  """magnitude frequency distribution of the filtered rutpures."""
  mfd_histogram: [MagFreqDist]
  color_scale(name: String, normalization: ColourScaleNormaliseEnum, min_value: Float, max_value: Float): ColorScale
}

type CompositeSolution {
  model_id: String
  fault_systems: [String]
}

enum ContentFormatEnum {
  Raw
  Markdown
}

enum ContentStatusEnum {
  Undefined
  Draft
  Published
  Deprecated
}

input CreateAggregateInversionSolutionInput {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]

  """
  ID of common rupture set. Aggregations must use solutions based on the same rupture set.
  """
  common_rupture_set: ID!

  """The solutions used to build the aggregate"""
  source_solutions: [ID]!

  """aggregation function on rupture rates."""
  aggregation_fn: AggregationFn!
  produced_by: ID

  """When the solution was created"""
  created: DateTime

  """list of predecessors"""
  predecessors: [PredecessorInput]
  clientMutationId: String
}

"""Create a AggregateInversionSolution file"""
type CreateAggregateInversionSolutionPayload {
  solution: AggregateInversionSolution
  ok: Boolean
  clientMutationId: String
}

type CreateAutomationTask {
  task_result: AutomationTask
}

type CreateFile {
  ok: Boolean
  file_result: File
}

type CreateFileRelation {
  ok: Boolean
  file_relation: FileRelation
}

input CreateGeneralTaskInput {
  """notes about the task, potentially Markdown"""
  notes: String

  """count of subtasks"""
  subtask_count: Int
  subtask_type: TaskSubType
  model_type: ModelType
  subtask_result: EventResult

  """When the taskrecord was created"""
  created: DateTime

  """The name of the person or process responsible for the task"""
  agent_name: String

  """A title always helps"""
  title: String

  """Some description of the task, potentially Markdown"""
  description: String

  """subtask arguments, as a list of Key Value List pairs."""
  argument_lists: [KeyValueListPairInput]

  """arbitrary metadata for the task, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]
  clientMutationId: String
}

type CreateGeneralTaskPayload {
  general_task: GeneralTask
  clientMutationId: String
}

input CreateInversionSolutionInput {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]

  """When the solution was created"""
  created: DateTime

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  produced_by: ID

  """list of predecessors"""
  predecessors: [PredecessorInput]
  tables: [LabelledTableRelationInput]

  """result metrics from the solution, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
  clientMutationId: String
}

input CreateInversionSolutionNrmlInput {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]

  """When the scaled solution file was created"""
  created: DateTime
  source_solution: ID

  """list of predecessors"""
  predecessors: [PredecessorInput]
  clientMutationId: String
}

"""Create a InversionSolutionNrml file"""
type CreateInversionSolutionNrmlPayload {
  inversion_solution_nrml: InversionSolutionNrml
  ok: Boolean
  clientMutationId: String
}

"""Create an Inversion Solution file"""
type CreateInversionSolutionPayload {
  inversion_solution: InversionSolution
  ok: Boolean
  clientMutationId: String
}

input CreateOpenquakeHazardConfigInput {
  """When the thing was created"""
  created: DateTime

  """List of Source NRML"""
  source_models: [ID]

  """ID of an archive file, containing the config inputs."""
  template_archive: ID
  clientMutationId: String
}

type CreateOpenquakeHazardConfigPayload {
  config: OpenquakeHazardConfig
  ok: Boolean
  clientMutationId: String
}

input CreateOpenquakeHazardSolutionInput {
  """When it was created (UTZ)"""
  created: DateTime
  config: ID!
  produced_by: ID!
  csv_archive: ID
  hdf5_archive: ID
  modified_config: ID
  task_args: ID

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]

  """result metrics from the solution, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]

  """list of predecessors"""
  predecessors: [PredecessorInput]
  clientMutationId: String
}

"""Create an OpenquakeHazardSolution"""
type CreateOpenquakeHazardSolutionPayload {
  openquake_hazard_solution: OpenquakeHazardSolution
  ok: Boolean
  clientMutationId: String
}

type CreateOpenquakeHazardTask {
  ok: Boolean
  openquake_hazard_task: OpenquakeHazardTask
}

type CreateRuptureGenerationTask {
  task_result: RuptureGenerationTask
}

input CreateScaledInversionSolutionInput {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]
  source_solution: ID
  produced_by: ID

  """When the solution was created"""
  created: DateTime

  """list of predecessors"""
  predecessors: [PredecessorInput]
  clientMutationId: String
}

"""Create a ScaledInversionSolution file"""
type CreateScaledInversionSolutionPayload {
  solution: ScaledInversionSolution
  ok: Boolean
  clientMutationId: String
}

type CreateSmsFile {
  ok: Boolean
  file_result: SmsFile
}

input CreateStrongMotionStationInput {
  """When the SMS record was created"""
  created: DateTime

  """When SMS record was updated"""
  updated: DateTime

  """A unique, four character SMS identifier"""
  site_code: String

  """The NZS1170.5 Site Class"""
  site_class: SmsSiteClass

  """The data source used for site classification"""
  site_class_basis: SmsSiteClassBasis

  """Array of Vs30 mean measurements"""
  Vs30_mean: [Float]

  """Array of Vs30 mean measurements"""
  Vs30_std_dev: [Float]

  """Indicate whether subsurface investigations have encountered bedrock"""
  bedrock_encountered: Boolean

  """Indicate presence of soils that can liquify"""
  liquefiable: Boolean

  """Indicate presence of soft clay or peat soils"""
  soft_clay_or_peat: Boolean
  clientMutationId: String
}

type CreateStrongMotionStationPayload {
  strong_motion_station: StrongMotionStation
  clientMutationId: String
}

input CreateTableInput {
  """a name for the table"""
  name: String

  """ID of the object this data relates to"""
  object_id: ID

  """When the task record was created"""
  created: DateTime

  """column headings"""
  column_headers: [String]

  """column types"""
  column_types: [RowItemType]

  """
  The table rows. Each row is a list of strings that can be coerced according to column_types.
  """
  rows: [[String]]

  """additional meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]
  table_type: TableType!

  """table dimensions, as a list of Key Value List pairs."""
  dimensions: [KeyValueListPairInput]
  clientMutationId: String
}

type CreateTablePayload {
  table: Table
  clientMutationId: String
}

type CreateTaskTaskRelation {
  ok: Boolean
  thing_relation: TaskTaskRelation
}

input CreateTimeDependentInversionSolutionInput {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]
  source_solution: ID
  produced_by: ID

  """When the solution was created"""
  created: DateTime

  """list of predecessors"""
  predecessors: [PredecessorInput]
  clientMutationId: String
}

"""Create a TimeDependentInversionSolution file"""
type CreateTimeDependentInversionSolutionPayload {
  solution: TimeDependentInversionSolution
  ok: Boolean
  clientMutationId: String
}

"""
The `DateTime` scalar type represents a DateTime
value as specified by
[iso8601](https://en.wikipedia.org/wiki/ISO_8601).
"""
scalar DateTime

"""All the info about a given disagg report."""
type DisaggregationReport {
  hazard_model: String
  location: HazardCodedLocation
  imt: String
  poe: Float
  vs30: Int
  inv_time: Int
  report_url: String
}

type DisaggregationReportResult {
  ok: Boolean
  reports: [DisaggregationReport]
}

enum EventResult {
  FAILURE
  PARTIAL
  SUCCESS
  UNDEFINED
}

enum EventState {
  SCHEDULED
  STARTED
  DONE
  UNDEFINED
}

type FaultSystemLogicTree {
  short_name: String
  long_name: String
  branches: [SourceLogicTreeBranch]
}

type FaultSystemLogicTreeSpec {
  short_name: String
  long_name: String
  branches: [BranchAttributeValueSpec]
}

type File implements Node & FileInterface & PredecessorsInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]
}

"""A Relay connection for Files"""
type FileConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [FileEdge]!
  total_count: Int
}

"""A Relay edge containing a `File` and its cursor."""
type FileEdge {
  """The item at the end of the edge"""
  node: File

  """A cursor for use in pagination"""
  cursor: String!
}

"""A File in the NSHM saga"""
interface FileInterface {
  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection
}

type FileRelation {
  thing: Thing
  file: FileUnion
  role: FileRole!
  thing_id: String
  file_id: String
}

type FileRelationConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [FileRelationEdge]!
  total_count: Int
}

"""A Relay edge containing a `FileRelation` and its cursor."""
type FileRelationEdge {
  """The item at the end of the edge"""
  node: FileRelation

  """A cursor for use in pagination"""
  cursor: String!
}

enum FileRole {
  READ
  WRITE
  READ_WRITE
  UNDEFINED
}

union FileUnion = SmsFile | File | InversionSolution | ScaledInversionSolution | AggregateInversionSolution | InversionSolutionNrml | TimeDependentInversionSolution

type FilterInversionSolution {
  analysis: InversionSolutionAnalysis
}

"""Arguments FilterRupturesArgs"""
type FilterRupturesArgs {
  """The ID of NSHM model"""
  model_id: String!

  """The fault systems [`HIK`, `PUY`, `CRU`]"""
  fault_system: String!

  """
  Optional list of locations ids for proximity filtering e.g. `WLG,PMR,ZQN`
  """
  location_ids: [String]

  """The rupture/location intersection radius in km"""
  radius_km: Int

  """
  Constrain to fault_sections having a annual rate above the value supplied.
  """
  minimum_rate: Float

  """
  Constrain to fault_sections having a annual rate below the value supplied.
  """
  maximum_rate: Float

  """
  Constrain to fault_sections having a magnitude above the value supplied.
  """
  minimum_mag: Float

  """
  Constrain to fault_sections having a magnitude below the value supplied.
  """
  maximum_mag: Float
}

"""Arguments passed as FilterRupturesArgs"""
input FilterRupturesArgsInput {
  """The ID of NSHM model"""
  model_id: String!

  """The fault systems [`HIK`, `PUY`, `CRU`]"""
  fault_system: String!

  """
  Optional list of locations ids for proximity filtering e.g. `WLG,PMR,ZQN`
  """
  location_ids: [String] = []

  """The rupture/location intersection radius in km"""
  radius_km: Int

  """
  Constrain to fault_sections having a annual rate above the value supplied.
  """
  minimum_rate: Float

  """
  Constrain to fault_sections having a annual rate below the value supplied.
  """
  maximum_rate: Float

  """
  Constrain to fault_sections having a magnitude above the value supplied.
  """
  minimum_mag: Float

  """
  Constrain to fault_sections having a magnitude below the value supplied.
  """
  maximum_mag: Float
}

type GeneralTask implements Node & Thing {
  id: ID!

  """When the task record was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """parent task(s) of this task"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """sub-tasks of this task"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """When the task record was last updated"""
  updated: DateTime

  """The name of the person or process responsible for the task"""
  agent_name: String

  """A title always helps"""
  title: String

  """Some description of the task, potentially Markdown"""
  description: String

  """subtask arguments, as a list of Key Value List pairs."""
  argument_lists: [KeyValueListPair]

  """list of keys for items having >1 value in argument_lists"""
  swept_arguments: [String]

  """arbitrary metadata for the task, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """notes about the task, potentially Markdown"""
  notes: String

  """count of subtasks"""
  subtask_count: Int
  subtask_type: TaskSubType
  model_type: ModelType
  subtask_result: EventResult
}

"""Defines styling arguments for geojson features"""
input GeojsonAreaStyleArgumentsInput {
  """
  stroke (line) colour as hex code ("#cc0000") or HTML color name ("royalblue")
  """
  stroke_color: String = "green"

  """a number between 0 and 20."""
  stroke_width: Int = 1

  """a number between 0 and 1.0"""
  stroke_opacity: Float = 1

  """
  fill colour as Hex code ("#cc0000") or HTML color names ("royalblue") )
  """
  fill_color: String = "green"

  """0-1.0"""
  fill_opacity: Float = 1
}

type GeoJsonHazardMap {
  geojson: JSONString
  colour_scale: HexRgbValueMapping
}

"""Defines styling arguments for geojson features"""
input GeojsonLineStyleArgumentsInput {
  """
  stroke (line) colour as hex code ("#cc0000") or HTML color name ("royalblue")
  """
  stroke_color: String = "green"

  """a number between 0 and 20."""
  stroke_width: Int = 1

  """a number between 0 and 1.0"""
  stroke_opacity: Float = 1
}

type GriddedHazard {
  grid_id: RegionGrid
  hazard_model: String
  imt: String
  agg: String
  vs30: Float
  poe: Float

  """Acceleration values."""
  values: [Float]
  hazard_map(color_scale: String = "jet", color_scale_vmax: Float, color_scale_vmin: Float = 0, color_scale_normalise: ColourScaleNormalise, stroke_width: Float, stroke_opacity: Float, fill_opacity: Float): GeoJsonHazardMap
  grid_locations: [GriddedLocation]
}

type GriddedHazardResult {
  gridded_hazard: [GriddedHazard]
  ok: Boolean
}

type GriddedLocation {
  lat: Float
  lon: Float
  code: String
  name: String
  key: String
  resolution: Float
}

type GriddedLocationResult {
  location: GriddedLocation
  ok: Boolean
}

type HazardCodedLocation {
  lat: Float
  lon: Float
  code: String
  name: String
  key: String
}

type HexRgbValueMapping {
  levels: [Float]
  hexrgbs: [String]
}

type InversionSolution implements Node & InversionSolutionInterface & FileInterface & PredecessorsInterface {
  id: ID!

  """When the solution was created"""
  created: DateTime

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  tables: [LabelledTableRelation]

  """deprecated"""
  hazard_table: Table

  """deprecated"""
  mfd_table: Table
  produced_by: AutomationTaskUnion

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]
}

"""
Represents the internal details of a given solution or filtered solution
"""
type InversionSolutionAnalysis {
  solution_id: ID
  fault_sections_geojson: JSONString
  location_geojson: JSONString
}

"""Defines filter arguments for Inversions analysis"""
input InversionSolutionAnalysisArguments {
  """The ID of the InversionSolution"""
  solution_id: ID!

  """
  Optional list of locations codes for proximity filtering e.g. `WLG,PMR,ZQN`
  """
  location_ids: [String] = []

  """The rupture/location intersection radius in km"""
  radius_km: Int

  """
  Constrain to fault_sections having a annual rate above the value supplied.
  """
  minimum_rate: Float

  """
  Constrain to fault_sections having a annual rate below the value supplied.
  """
  maximum_rate: Float

  """
  Constrain to fault_sections having a magnitude above the value supplied.
  """
  minimum_mag: Float

  """
  Constrain to fault_sections having a magnitude below the value supplied.
  """
  maximum_mag: Float

  """feature style for rupture trace geojson."""
  fault_trace_style: GeojsonLineStyleArgumentsInput = {stroke_color: "black", stroke_width: 1, stroke_opacity: 1}

  """feature style for location polygons."""
  location_area_style: GeojsonAreaStyleArgumentsInput = {stroke_color: "lightblue", stroke_width: 1, stroke_opacity: 1, fill_color: "lightblue", fill_opacity: 0.7}
}

"""A interface for things like Inversion Solution"""
interface InversionSolutionInterface {
  """When the solution was created"""
  created: DateTime

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  tables: [LabelledTableRelation]

  """deprecated"""
  hazard_table: Table

  """deprecated"""
  mfd_table: Table
  produced_by: AutomationTaskUnion
}

type InversionSolutionNrml implements Node & FileInterface & PredecessorsInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]

  """When the scaled solution file was created"""
  created: DateTime

  """The original solution."""
  source_solution: SourceSolutionUnion
}

"""
Allows use of a JSON String for input / output from the GraphQL schema.

Use of this type is *not recommended* as you lose the benefits of having a defined, static
schema (one of the key benefits of GraphQL).
"""
scalar JSONString

"""Simple container for KVL lists of strings"""
type KeyValueListPair {
  """key"""
  k: String

  """list of values"""
  v: [String]
}

"""Simple container for KVL lists of strings"""
input KeyValueListPairInput {
  """key"""
  k: String

  """list of values"""
  v: [String]
}

"""Simple container for string-based KV pair data"""
type KeyValuePair {
  """key"""
  k: String

  """value"""
  v: String
}

"""Simple container for string-based KV pair data"""
input KeyValuePairInput {
  """key"""
  k: String

  """value"""
  v: String
}

"""
a unique, labelled table relationship.

This is intended to be used as an internal structure within an InversionSolution (or similar).
It must be stored internally in the parent object, so does not implement the
node interface. New instances must be mutated via the
parent class.
"""
type LabelledTableRelation {
  """an internal unique UUID to support mutations."""
  identity: String

  """When the task record was created."""
  created: DateTime

  """the object responsible for creating this relationship."""
  produced_by_id: ID

  """Label used to differentiate this relationsip for humans."""
  label: String

  """the ID of the table"""
  table_id: ID
  table: Table

  """table type"""
  table_type: TableType

  """table dimensions, as a list of Key Value List pairs."""
  dimensions: [KeyValueListPair]
}

input LabelledTableRelationInput {
  """the object responsible for creating this relationship."""
  produced_by_id: ID

  """Label used to differentiate this relationsip for humans."""
  label: String

  """the ID of the table"""
  table_id: ID

  """table type"""
  table_type: TableType

  """table dimensions, as a list of Key Value List pairs."""
  dimensions: [KeyValueListPairInput]
}

type Location {
  """unique location location_id."""
  location_id: String

  """location name."""
  name: String

  """location latitude."""
  latitude: Float

  """location longitude"""
  longitude: Float
}

type LocationDetail implements Node {
  id: ID!
  location_id: String
  name: String
  latitude: Float
  longitude: Float
  radius_geojson(
    """polygon radius (km)."""
    radius_km: Int!

    """feature style for the geojson."""
    style: GeojsonAreaStyleArgumentsInput = {stroke_color: "black", stroke_width: 1, stroke_opacity: 1, fill_color: "green", fill_opacity: 1}
  ): JSONString
}

type LocationDetailConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [LocationDetailEdge]!
  total_count: Int
}

"""A Relay edge containing a `LocationDetail` and its cursor."""
type LocationDetailEdge {
  """The item at the end of the edge"""
  node: LocationDetail

  """A cursor for use in pagination"""
  cursor: String!
}

type LocationList {
  """The unique location_list_id"""
  list_id: String

  """list of location codes."""
  location_ids: [String]

  """the locations in this list."""
  locations: [Location]
}

type MagFreqDist {
  bin_center: Float
  rate: Float
  cumulative_rate: Float
}

enum ModelType {
  CRUSTAL
  SUBDUCTION
  COMPOSITE
}

type Mutation {
  """Append LabelledTableRelationTable to an existing Inversion Solution"""
  TOSHI_append_inversion_solution_tables(input: AppendInversionSolutionTablesInput!): AppendInversionSolutionTablesPayload
  TOSHI_create_automation_task(input: NewAutomationTaskInput!): CreateAutomationTask
  TOSHI_create_file(
    file_name: String
    file_size: BigInt
    md5_digest: String = "The base64-encoded md5 digest of the file"

    """additional file meta data, as a list of Key Value pairs."""
    meta: [KeyValuePairInput]

    """list of predecessors"""
    predecessors: [PredecessorInput]
  ): CreateFile
  TOSHI_create_file_relation(file_id: ID!, role: FileRole!, thing_id: ID!): CreateFileRelation
  TOSHI_create_general_task(input: CreateGeneralTaskInput!): CreateGeneralTaskPayload

  """Create an Inversion Solution file"""
  TOSHI_create_inversion_solution(input: CreateInversionSolutionInput!): CreateInversionSolutionPayload
  TOSHI_create_rupture_generation_task(input: AutomationTaskInput!): CreateRuptureGenerationTask
  TOSHI_create_sms_file(file_name: String, file_size: BigInt, file_type: SmsFileType!, md5_digest: String = "The base64-encoded md5 digest of the file"): CreateSmsFile
  TOSHI_create_strong_motion_station(input: CreateStrongMotionStationInput!): CreateStrongMotionStationPayload
  TOSHI_create_table(input: CreateTableInput!): CreateTablePayload
  TOSHI_create_task_relation(child_id: ID!, parent_id: ID!): CreateTaskTaskRelation
  TOSHI_update_automation_task(input: AutomationTaskUpdateInput!): UpdateAutomationTask
  TOSHI_update_general_task(input: UpdateGeneralTaskInput!): UpdateGeneralTaskPayload
  TOSHI_update_rupture_generation_task(input: AutomationTaskUpdateInput!): UpdateRuptureGenerationTask

  """Create a AggregateInversionSolution file"""
  TOSHI_create_aggregate_inversion_solution(input: CreateAggregateInversionSolutionInput!): CreateAggregateInversionSolutionPayload

  """Create a ScaledInversionSolution file"""
  TOSHI_create_scaled_inversion_solution(input: CreateScaledInversionSolutionInput!): CreateScaledInversionSolutionPayload

  """Create a TimeDependentInversionSolution file"""
  TOSHI_create_time_dependent_inversion_solution(input: CreateTimeDependentInversionSolutionInput!): CreateTimeDependentInversionSolutionPayload

  """Create a InversionSolutionNrml file"""
  TOSHI_create_inversion_solution_nrml(input: CreateInversionSolutionNrmlInput!): CreateInversionSolutionNrmlPayload

  """Create an OpenquakeHazardSolution"""
  TOSHI_create_openquake_hazard_solution(input: CreateOpenquakeHazardSolutionInput!): CreateOpenquakeHazardSolutionPayload
  TOSHI_create_openquake_hazard_config(input: CreateOpenquakeHazardConfigInput!): CreateOpenquakeHazardConfigPayload
  TOSHI_create_openquake_hazard_task(input: OpenquakeHazardTaskInput!): CreateOpenquakeHazardTask
  TOSHI_update_openquake_hazard_task(input: OpenquakeHazardTaskUpdateInput!): UpdateOpenquakeHazardTask
}

input NewAutomationTaskInput {
  result: EventResult!
  state: EventState!

  """The time the task was created"""
  created: DateTime!

  """The final duraton of the task in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePairInput]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePairInput]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
  model_type: ModelType
  task_type: TaskSubType!
}

interface Node {
  id: ID!
}

type NodeFilter {
  ok: Boolean
  result(before: String, after: String, first: Int, last: Int): SearchResultConnection
}

type NzshmModel {
  version: String
  title: String
  source_logic_tree: SourceLogicTree
  source_logic_tree_spec: SourceLogicTreeSpec
}

type NzshmModelResult {
  model: NzshmModel
  ok: Boolean
}

type OpenquakeHazardConfig implements Node & Thing {
  id: ID!

  """When the thing was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """Parents of this thing"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """List of Source NRML files"""
  source_models: [OpenquakeNrmlUnion]

  """
  An archive of all the configuration files (besides those in source_models
  """
  template_archive: File
}

type OpenquakeHazardSolution implements Node & Thing & PredecessorsInterface {
  id: ID!

  """When it was created (UTZ)"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """Parents of this thing"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]

  """the template configuration used to produce this solution"""
  config: OpenquakeHazardConfig

  """
  a zip archive containing hazard csv outputs (`oq engine --export-outputs ....)
  """
  csv_archive: File

  """a zip archive containing containing the raw hdf5"""
  hdf5_archive: File

  """a zip archive containing modified config files."""
  modified_config: File

  """task arguments json file."""
  task_args: File

  """result metrics from the solution, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """result metrics from the solution, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """The task that produced this solution"""
  produced_by: OpenquakeHazardTask
}

type OpenquakeHazardTask implements Node & Thing & AutomationTaskInterface {
  id: ID!

  """The time the event was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """parent task(s) of this task"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection
  result: EventResult
  state: EventState

  """the final duration of the event in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePair]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePair]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """The task configuration"""
  config: OpenquakeHazardConfig

  """The openquake solution"""
  hazard_solution: OpenquakeHazardSolution
  model_type: ModelType
}

input OpenquakeHazardTaskInput {
  result: EventResult!
  state: EventState!

  """The time the task was created"""
  created: DateTime!

  """The final duraton of the task in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePairInput]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePairInput]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
  config: ID!
  model_type: ModelType!
}

input OpenquakeHazardTaskUpdateInput {
  task_id: ID!
  result: EventResult
  state: EventState

  """The final duraton of the task in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePairInput]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePairInput]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePairInput]
  hazard_solution: ID
}

"""Some NRML files are just files i.e BG seismicity XML."""
union OpenquakeNrmlUnion = File | InversionSolutionNrml

"""
The Relay compliant `PageInfo` type, containing data necessary to paginate this connection.
"""
type PageInfo {
  """When paginating forwards, are there more items?"""
  hasNextPage: Boolean!

  """When paginating backwards, are there more items?"""
  hasPreviousPage: Boolean!

  """When paginating backwards, the cursor to continue."""
  startCursor: String

  """When paginating forwards, the cursor to continue."""
  endCursor: String
}

type Person {
  name: String
}

"""Represents a something that came before this thing."""
type Predecessor {
  """The id of the predecessor object"""
  id: ID

  """The typename of the predecessor object"""
  typename: String

  """The predecessor relationship numerically"""
  depth: Int

  """The predecessor relationship in Title case."""
  relationship: String
  node: PredecessorUnion
}

"""Represents a something that came before this thing."""
input PredecessorInput {
  """The id of the predecessor object"""
  id: ID

  """The predecessor relationship numerically"""
  depth: Int
}

"""A interface for things having predecessors"""
interface PredecessorsInterface {
  """list of predecessor info"""
  predecessors: [Predecessor]
}

union PredecessorUnion = File | InversionSolution | ScaledInversionSolution | InversionSolutionNrml | TimeDependentInversionSolution

enum ProjectAreaEnum {
  Core
  GMCM
  SRM
}

type Query {
  """List Opensha Rupture Generation tasks."""
  TOSHI_rupture_generation_tasks(before: String, after: String, first: Int, last: Int): RuptureGenerationTaskConnection

  """The files."""
  TOSHI_files(before: String, after: String, first: Int, last: Int): FileConnection
  TOSHI_node(
    """The ID of the object"""
    id: ID!
  ): Node
  TOSHI_nodes(id_in: [ID]): NodeFilter
  TOSHI_search(search_term: String): Search
  TOSHI_strong_motion_station(id: ID!): StrongMotionStation

  """The list of strong motion stations"""
  TOSHI_strong_motion_stations(before: String, after: String, first: Int, last: Int): StrongMotionStationConnection
  KORORAA_node(
    """The ID of the object"""
    id: ID!
  ): Node

  """About this API """
  KORORAA_about: String
  KORORAA_nzshm_model(version: String): NzshmModelResult
  KORORAA_nzshm_models: [NzshmModelResult]
  KORORAA_disaggregation_reports: DisaggregationReportResult
  KORORAA_science_reports: ScienceReportResult
  KORORAA_textual_content(index: String, tags: [String]): TextualContentResult
  KORORAA_gridded_location(lat: Float, lon: Float, resolution: Float): GriddedLocationResult
  KORORAA_hazard_curves(hazard_model: String, imts: [String], locs: [String], aggs: [String], vs30s: [Int], resolution: Float = 0.1): ToshiHazardCurveResult
  KORORAA_gridded_hazard(grid_id: RegionGrid, hazard_model_id: String, imt: String, loc: String, agg: String, vs30: Int, poe: Float): GriddedHazardResult
  SOLVIS_color_scale(name: String, min_value: Float, max_value: Float, normalization: ColourScaleNormaliseEnum): ColorScale
  SOLVIS_node(
    """The ID of the object"""
    id: ID!
  ): Node

  """About this Solvis API """
  SOLVIS_about: String
  SOLVIS_inversion_solution(filter: InversionSolutionAnalysisArguments!): FilterInversionSolution
  SOLVIS_locations_by_id(
    """list of nzshm_common.location_ids e.g. `["WLG","PMR","ZQN"]`"""
    location_ids: [String]!
  ): LocationDetailConnection
  SOLVIS_composite_solution(
    """A valid NSHM model id e.g. `NSHM_1.0.0`"""
    model_id: String!
  ): CompositeSolution
  SOLVIS_composite_rupture_detail(filter: CompositeRuptureDetailArgs!): CompositeRuptureDetail
  SOLVIS_filter_ruptures(filter: FilterRupturesArgsInput!, sortby: [SimpleSortRupturesArgs] = [], before: String, after: String, first: Int, last: Int): RuptureDetailConnection
  SOLVIS_filter_rupture_sections(filter: FilterRupturesArgsInput!): CompositeRuptureSections

  """Return ad single radii_set for the id passed in"""
  SOLVIS_get_radii_set(
    """the integer ID for the desired radii_set"""
    radii_set_id: Int!
  ): RadiiSet

  """Return all the available radii_set"""
  SOLVIS_get_radii_sets: [RadiiSet]

  """Return a single location."""
  SOLVIS_get_location(
    """the location code of the desired location"""
    location_id: String!
  ): Location

  """Return all the available locations"""
  SOLVIS_get_locations: [Location]

  """Return a single location list."""
  SOLVIS_get_location_list(
    """the id of the desired location_list"""
    list_id: String!
  ): LocationList

  """Return all the available location lists"""
  SOLVIS_get_location_lists: [LocationList]
  node(id: ID!): Node
}

type RadiiSet {
  """The unique radii_set_id"""
  radii_set_id: Int

  """list of dimension in metres defined by the radii set."""
  radii: [Int]
}

"""An enumeration."""
enum RegionGrid {
  NZ_0_1_NB_1_0
  NZ_0_1_NB_1_1
  NZ_0_2_NB_1_1
  WLG_0_01_nb_1_1
  WLG_0_05_nb_1_1
}

enum ReportStatusEnum {
  Undefined
  Review
  Published
}

"""Data type"""
enum RowItemType {
  integer
  double
  string
  boolean
}

type RuptureDetailConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [RuptureDetailEdge]!
  total_count: Int
}

"""A Relay edge containing a `RuptureDetail` and its cursor."""
type RuptureDetailEdge {
  """The item at the end of the edge"""
  node: CompositeRuptureDetail

  """A cursor for use in pagination"""
  cursor: String!
}

type RuptureGenerationTask implements Node & Thing & AutomationTaskInterface {
  id: ID!

  """The time the event was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """parent task(s) of this task"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection
  result: EventResult
  state: EventState

  """the final duration of the event in seconds"""
  duration: Float

  """
  input arguments for the rupture generation task, as a list of Key Value pairs.
  """
  arguments: [KeyValuePair]

  """execution environment details, as a list of Key Value pairs."""
  environment: [KeyValuePair]

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]
}

"""A list of RuptureGenerationTask items"""
type RuptureGenerationTaskConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [RuptureGenerationTaskEdge]!
  total_count: Int
}

"""A Relay edge containing a `RuptureGenerationTask` and its cursor."""
type RuptureGenerationTaskEdge {
  """The item at the end of the edge"""
  node: RuptureGenerationTask

  """A cursor for use in pagination"""
  cursor: String!
}

type ScaledInversionSolution implements Node & FileInterface & PredecessorsInterface & InversionSolutionInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]

  """When the solution was created"""
  created: DateTime

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  tables: [LabelledTableRelation]

  """deprecated"""
  hazard_table: Table

  """deprecated"""
  mfd_table: Table
  produced_by: AutomationTaskUnion

  """The original soloution as produced by opensha"""
  source_solution: InversionSolution
}

"""NSHM Science report publication details."""
type ScienceReport {
  title: String
  topic: String
  filename: String
  area: ProjectAreaEnum
  status: ReportStatusEnum

  """Internal notes, not for UI."""
  notes: String

  """publication date"""
  publication_date: DateTime
  report_number: String
  lead_author: Person
  reviewers: [Person]
  bibliographic_ref: String
}

type ScienceReportResult {
  ok: Boolean
  reports: [ScienceReport]
}

type Search {
  ok: Boolean
  search_result(before: String, after: String, first: Int, last: Int): SearchResultConnection
}

union SearchResult = File | RuptureGenerationTask | StrongMotionStation | SmsFile | GeneralTask | Table | InversionSolution | AutomationTask | ScaledInversionSolution | TimeDependentInversionSolution

type SearchResultConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [SearchResultEdge]!
  total_count: Int
}

"""A Relay edge containing a `SearchResult` and its cursor."""
type SearchResultEdge {
  """The item at the end of the edge"""
  node: SearchResult

  """A cursor for use in pagination"""
  cursor: String!
}

input SimpleSortRupturesArgs {
  attribute: String
  ascending: Boolean
}

type SmsFile implements Node & FileInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection
  file_type: SmsFileType!
}

enum SmsFileType {
  BH
  CPT
  DH
  HVSR
  SW
}

"""NZS1170.5 Site Class, one of A,B,C,D,E"""
enum SmsSiteClass {
  A
  B
  C
  D
  E
}

"""NZS1170.5 Site Class Basis, one of Vs,SPT,su"""
enum SmsSiteClassBasis {
  Vs
  SPT
  su
}

type SourceLogicTree {
  fault_system_branches: [FaultSystemLogicTree]
}

type SourceLogicTreeBranch {
  weight: Float
  onfault_nrml_id: ID
  distributed_nrml_id: ID
  inversion_solution_id: ID
  inversion_solution_type: String
  values: [BranchAttributeValue]
  source_solution: SourceSolutionUnion
}

type SourceLogicTreeSpec {
  fault_system_branches: [FaultSystemLogicTreeSpec]
}

union SourceSolutionUnion = InversionSolution | ScaledInversionSolution | TimeDependentInversionSolution

type StrongMotionStation implements Node & Thing {
  id: ID!

  """When the SMS record was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """Parents of this thing"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """When SMS record was updated"""
  updated: DateTime

  """A unique, four character SMS identifier"""
  site_code: String

  """The NZS1170.5 Site Class"""
  site_class: SmsSiteClass

  """The data source used for site classification"""
  site_class_basis: SmsSiteClassBasis

  """Array of Vs30 mean measurements"""
  Vs30_mean: [Float]

  """Array of Vs30 mean measurements"""
  Vs30_std_dev: [Float]

  """Indicate whether subsurface investigations have encountered bedrock"""
  bedrock_encountered: Boolean

  """Indicate presence of soils that can liquify"""
  liquefiable: Boolean

  """Indicate presence of soft clay or peat soils"""
  soft_clay_or_peat: Boolean
}

"""A list of StrongMotionStation items"""
type StrongMotionStationConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [StrongMotionStationEdge]!
}

"""A Relay edge containing a `StrongMotionStation` and its cursor."""
type StrongMotionStationEdge {
  """The item at the end of the edge"""
  node: StrongMotionStation

  """A cursor for use in pagination"""
  cursor: String!
}

type Table implements Node {
  id: ID!

  """a name for the table"""
  name: String

  """ID of the object this data relates to"""
  object_id: ID

  """When the task record was created"""
  created: DateTime

  """column headings"""
  column_headers: [String]

  """column types"""
  column_types: [RowItemType]

  """
  The table rows. Each row is a list of strings that can be coerced according to column_types.
  """
  rows: [[String]]

  """additional meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """table type"""
  table_type: TableType

  """table dimensions, as a list of Key Value List pairs."""
  dimensions: [KeyValueListPair]
}

"""Data type"""
enum TableType {
  HAZARD_GRIDDED
  HAZARD_SITES
  MFD_CURVES
  MFD_CURVES_V2
  GENERAL
}

enum TaskSubType {
  RUPTURE_SET
  INVERSION
  HAZARD
  REPORT
  SCALE_SOLUTION
  AGGREGATE_SOLUTION
  SOLUTION_TO_NRML
  OPENQUAKE_HAZARD
  TIME_DEPENDENT_SOLUTION
}

type TaskTaskRelation {
  parent: GeneralTask
  child: ChildTaskUnion
  parent_id: String
  child_id: String
}

type TaskTaskRelationConnection {
  """Pagination data for this connection."""
  pageInfo: PageInfo!

  """Contains the nodes in this connection."""
  edges: [TaskTaskRelationEdge]!
  total_count: Int
}

"""A Relay edge containing a `TaskTaskRelation` and its cursor."""
type TaskTaskRelationEdge {
  """The item at the end of the edge"""
  node: TaskTaskRelation

  """A cursor for use in pagination"""
  cursor: String!
}

"""NSHM textual content details."""
type TextualContent {
  index: String
  content_type: ContentFormatEnum
  author: String
  tags: [String]
  status: ContentStatusEnum

  """created date"""
  created: DateTime
  text: String
}

type TextualContentResult {
  ok: Boolean
  content: [TextualContent]
}

"""A Thing in the NSHM saga"""
interface Thing {
  """When the thing was created"""
  created: DateTime

  """Files associated with this object."""
  files(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """Parents of this thing"""
  parents(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection

  """Children of this thing"""
  children(before: String, after: String, first: Int, last: Int): TaskTaskRelationConnection
}

type TimeDependentInversionSolution implements Node & FileInterface & PredecessorsInterface & InversionSolutionInterface {
  id: ID!

  """The name of the file"""
  file_name: String

  """The base64-encoded md5 digest of the file"""
  md5_digest: String

  """The size of the file in bytes"""
  file_size: BigInt

  """A pre-signed URL to download the file from s3"""
  file_url: String

  """A pre-signed URL to post the data to s3"""
  post_url: String

  """additional file meta data, as a list of Key Value pairs."""
  meta: [KeyValuePair]

  """things related to this data file"""
  relations(before: String, after: String, first: Int, last: Int): FileRelationConnection

  """list of predecessor info"""
  predecessors: [Predecessor]

  """When the solution was created"""
  created: DateTime

  """result metrics from the task, as a list of Key Value pairs."""
  metrics: [KeyValuePair]

  """deprecated"""
  mfd_table_id: ID
  hazard_table_id: ID
  tables: [LabelledTableRelation]

  """deprecated"""
  hazard_table: Table

  """deprecated"""
  mfd_table: Table
  produced_by: AutomationTaskUnion

  """The original soloution as produced by opensha"""
  source_solution: InversionSolution
}

"""Represents one set of level and values for a hazard curve."""
type ToshiHazardCurve {
  """IMT levels."""
  levels: [Float]

  """Hazard values."""
  values: [Float]
}

type ToshiHazardCurveResult {
  ok: Boolean
  locations: [GriddedLocation]
  curves: [ToshiHazardResult]
}

"""All the info about a given curve."""
type ToshiHazardResult {
  hazard_model: String
  loc: String
  imt: String
  agg: String
  vs30: Float
  curve: ToshiHazardCurve
}

type UpdateAutomationTask {
  task_result: AutomationTask
}

input UpdateGeneralTaskInput {
  """When the task record was created"""
  created: DateTime

  """When the task record was last updated"""
  updated: DateTime

  """The name of the person or process responsible for the task"""
  agent_name: String

  """A title always helps"""
  title: String

  """Some description of the task, potentially Markdown"""
  description: String

  """notes about the task, potentially Markdown"""
  notes: String

  """count of subtasks"""
  subtask_count: Int
  subtask_type: TaskSubType
  model_type: ModelType
  subtask_result: EventResult
  task_id: ID!

  """subtask arguments, as a list of Key Value List pairs."""
  argument_lists: [KeyValueListPairInput]

  """arbitrary metadata for the task, as a list of Key Value pairs."""
  meta: [KeyValuePairInput]
  clientMutationId: String
}

type UpdateGeneralTaskPayload {
  general_task: GeneralTask
  ok: Boolean
  clientMutationId: String
}

type UpdateOpenquakeHazardTask {
  ok: Boolean
  openquake_hazard_task: OpenquakeHazardTask
}

type UpdateRuptureGenerationTask {
  task_result: RuptureGenerationTask
}

